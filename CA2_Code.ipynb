{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5aed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69ac448",
   "metadata": {},
   "outputs": [],
   "source": [
    "customSchema = StructType([\n",
    "    StructField(\"Primary_Index\", IntegerType(), True), \n",
    "    StructField(\"Tweet_Id\", StringType(), True), \n",
    "    StructField(\"Date_Text\", StringType(), True),\n",
    "    StructField(\"Flag\", StringType(), True), \n",
    "    StructField(\"User\", StringType(), True),\n",
    "    StructField(\"Tweet_Text\", StringType(), True)])\n",
    "\n",
    "df = spark.read.load('hdfs://localhost:9000/CA2/ProjectTweets.csv', format=\"csv\", header=\"False\", sep=',', schema=customSchema)\n",
    "\n",
    "df = df.filter(df[\"Tweet_Id\"] == '1467811594')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb02d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove commas from the Tweet Text field\n",
    "##First test an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0bb486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------+\n",
      "|Tweet_Text                                                                                         |\n",
      "+---------------------------------------------------------------------------------------------------+\n",
      "|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?|\n",
      "+---------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df = df.filter(df[\"Tweet_Id\"] == '1467811594')\n",
    "# Select only the \"Tweet_Text\" column from the filtered DataFrame\n",
    "result = filtered_df.select(\"Tweet_Text\")\n",
    "\n",
    "# Show the content of column \"Tweet_Text\"\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fcd4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Then strip the commas out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec30428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|Tweet_Text                                                                                      |\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|@LOLTrish hey  long time no see! Yes.. Rains a bit only a bit  LOL  I'm fine thanks  how's you ?|\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "# Remove commas from the \"Tweet_Text\" column\n",
    "\n",
    "filtered_df = df.filter(df[\"Tweet_Id\"] == '1467811594')\n",
    "\n",
    "filtered_df = filtered_df.withColumn(\"Tweet_Text\", regexp_replace(filtered_df[\"Tweet_Text\"], \",\", \"\"))\n",
    "\n",
    "# Select only the \"Tweet_Text\" column from the filtered DataFrame\n",
    "result = filtered_df.select(\"Tweet_Text\")\n",
    "\n",
    "# Show the content of column \"Tweet_Text\"\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2fa28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now do it with all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1888c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Tweet_Text\", regexp_replace(df[\"Tweet_Text\"], \",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622797b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|Tweet_Text                                                                                      |\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "|@LOLTrish hey  long time no see! Yes.. Rains a bit only a bit  LOL  I'm fine thanks  how's you ?|\n",
      "+------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df = df.filter(df[\"Tweet_Id\"] == '1467811594')\n",
    "# Select only the \"Tweet_Text\" column from the filtered DataFrame\n",
    "result = filtered_df.select(\"Tweet_Text\")\n",
    "\n",
    "# Show the content of column \"Tweet_Text\"\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa63413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of Primary_Index: 1\n",
      "Max length of Tweet_Id: 10\n",
      "Max length of Date_Text: 28\n",
      "Max length of Flag: 8\n",
      "Max length of User: 4\n",
      "Max length of Tweet_Text: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the max length of each column\n",
    "from pyspark.sql.functions import max, length\n",
    "max_lengths = []\n",
    "\n",
    "for column_name in df.columns:\n",
    "    max_length = df.agg(max(length(column_name))).collect()[0][0]\n",
    "    max_lengths.append((column_name, max_length))\n",
    "\n",
    "# Display the results\n",
    "for col, max_len in max_lengths:\n",
    "    print(f\"Max length of {col}: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4388a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in Primary_Index: 0\n",
      "Number of null values in Tweet_Id: 0\n",
      "Number of null values in Date_Text: 0\n",
      "Number of null values in Flag: 0\n",
      "Number of null values in User: 0\n",
      "Number of null values in Tweet_Text: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Count null values in each column\n",
    "null_counts = []\n",
    "\n",
    "for column_name in df.columns:\n",
    "    count = df.select(column_name).where(col(column_name).isNull()).count()\n",
    "    null_counts.append((column_name, count))\n",
    "\n",
    "# Display the results\n",
    "for col, count in null_counts:\n",
    "    print(f\"Number of null values in {col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb930ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in Primary_Index: 1\n",
      "Number of unique values in Tweet_Id: 1\n",
      "Number of unique values in Date_Text: 1\n",
      "Number of unique values in Flag: 1\n",
      "Number of unique values in User: 1\n",
      "Number of unique values in Tweet_Text: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 72:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Calculate the number of unique values in each column\n",
    "unique_counts = []\n",
    "\n",
    "for column_name in df.columns:\n",
    "    count = df.agg(countDistinct(column_name)).collect()[0][0]\n",
    "    unique_counts.append((column_name, count))\n",
    "\n",
    "# Display the results\n",
    "for col, count in unique_counts:\n",
    "    print(f\"Number of unique values in {col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7065ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Tweet_Id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Find and display an example record with duplicated \"Tweet_Id\"\n",
    "duplicate_tweet_id_example = df.groupBy(\"Tweet_Id\").count().filter(col(\"count\") > 1).limit(1)\n",
    "\n",
    "# Display the result\n",
    "duplicate_tweet_id_example.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf779b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------+----+----+----------+\n",
      "|Primary_Index|Tweet_Id|Date_Text|Flag|User|Tweet_Text|\n",
      "+-------------+--------+---------+----+----+----------+\n",
      "+-------------+--------+---------+----+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find and display all records with the Tweet_Id \"1469531660\"\n",
    "matching_records = df.filter(col(\"Tweet_Id\") == \"1469531660\")\n",
    "\n",
    "# Display the matching records\n",
    "matching_records.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c469069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with unique records\n",
    "unique_records_df = df.dropDuplicates([\"Tweet_Id\", \"Date_Text\", \"Flag\", \"User\", \"Tweet_Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f72334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in Primary_Index: 1\n",
      "Number of unique values in Tweet_Id: 1\n",
      "Number of unique values in Date_Text: 1\n",
      "Number of unique values in Flag: 1\n",
      "Number of unique values in User: 1\n",
      "Number of unique values in Tweet_Text: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 117:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique values in each column\n",
    "unique_counts = []\n",
    "\n",
    "for column_name in df.columns:\n",
    "    count = unique_records_df.agg(countDistinct(column_name)).collect()[0][0]\n",
    "    unique_counts.append((column_name, count))\n",
    "\n",
    "# Display the results\n",
    "for col, count in unique_counts:\n",
    "    print(f\"Number of unique values in {col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41641c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 123:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------+----+----+----------+\n",
      "|Primary_Index|Tweet_Id|Date_Text|Flag|User|Tweet_Text|\n",
      "+-------------+--------+---------+----+----+----------+\n",
      "+-------------+--------+---------+----+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Find and display all records with the Tweet_Id \"1469531660\"\n",
    "matching_records = unique_records_df.filter(col(\"Tweet_Id\") == \"1469531660\")\n",
    "\n",
    "# Display the matching records\n",
    "matching_records.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18036c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unique_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fdd6bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 126:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Date_Text_Characters|\n",
      "+--------------------+\n",
      "|                 PDT|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 126:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extract characters at positions 21, 22, and 23 and select unique values\n",
    "from pyspark.sql.functions import substring\n",
    "unique_characters = df.select(substring(\"Date_Text\", 21, 3).alias(\"Date_Text_Characters\")).distinct()\n",
    "\n",
    "# Show the unique characters\n",
    "unique_characters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd47077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df =df.withColumn(\"Year\", df.Date_Text.substr(-4, 4))\n",
    "df = df.withColumn(\"Month\", df.Date_Text.substr(5, 3))\n",
    "df = df.withColumn(\"Day\", df.Date_Text.substr(9, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9436edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 129:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+\n",
      "|Primary_Index|  Tweet_Id|           Date_Text|    Flag|User|          Tweet_Text|Year|Month|Day|\n",
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+\n",
      "|            7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|coZZ|@LOLTrish hey  lo...|2009|  Apr| 06|\n",
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 129:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc901da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Month|\n",
      "+-----+\n",
      "|  Apr|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use the `distinct` method to get unique values in the \"Month\" column\n",
    "unique_months = df.select(\"Month\").distinct()\n",
    "\n",
    "# Show the unique values\n",
    "unique_months.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a44d551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 135:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+\n",
      "|Primary_Index|  Tweet_Id|           Date_Text|    Flag|User|          Tweet_Text|Year|Month|Day|\n",
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+\n",
      "|            7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|coZZ|@LOLTrish hey  lo...|2009|   04| 06|\n",
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# Use the `when` and `lit` functions to replace values in the \"Month\" column\n",
    "df = df.withColumn(\"Month\", when(df[\"Month\"] == \"May\", lit(\"05\"))\n",
    "                        .when(df[\"Month\"] == \"Apr\", lit(\"04\"))\n",
    "                        .when(df[\"Month\"] == \"Jun\", lit(\"06\"))\n",
    "                        .otherwise(df[\"Month\"]))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c6f781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 138:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+----------+\n",
      "|Primary_Index|  Tweet_Id|           Date_Text|    Flag|User|          Tweet_Text|Year|Month|Day|      Date|\n",
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+----------+\n",
      "|            7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|coZZ|@LOLTrish hey  lo...|2009|   04| 06|2009-04-06|\n",
      "+-------------+----------+--------------------+--------+----+--------------------+----+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws, expr\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Convert the \"Year,\" \"Month,\" and \"Day\" columns to string type\n",
    "df = df.withColumn(\"Year\", df[\"Year\"].cast(StringType()))\n",
    "df = df.withColumn(\"Month\", df[\"Month\"].cast(StringType()))\n",
    "df = df.withColumn(\"Day\", df[\"Day\"].cast(StringType()))\n",
    "\n",
    "# Use `concat_ws` to concatenate the three columns with \"/\" separator\n",
    "df = df.withColumn(\"Date\", concat_ws(\"/\", df[\"Day\"], df[\"Month\"], df[\"Year\"]))\n",
    "\n",
    "# Use `expr` to cast the concatenated string to a date\n",
    "df = df.withColumn(\"Date\", expr(\"to_date(Date, 'dd/MM/yyyy')\"))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99c554eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 141:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------------------+--------+----+------------------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "|Primary_Index|Tweet_Id  |Date_Text                   |Flag    |User|Tweet_Text                                                                                      |Year|Month|Day|Date      |\n",
      "+-------------+----------+----------------------------+--------+----+------------------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "|7            |1467811594|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|coZZ|@loltrish hey  long time no see! yes.. rains a bit only a bit  lol  i'm fine thanks  how's you ?|2009|04   |06 |2009-04-06|\n",
      "+-------------+----------+----------------------------+--------+----+------------------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 141:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower\n",
    "\n",
    "df = df.withColumn(\"Tweet_Text\", lower(col(\"Tweet_Text\")))\n",
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e13259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------------------+--------+----+------------------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "|Primary_Index|Tweet_Id  |Date_Text                   |Flag    |User|Tweet_Text                                                                                      |Year|Month|Day|Date      |\n",
      "+-------------+----------+----------------------------+--------+----+------------------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "|7            |1467811594|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|coZZ|@loltrish hey  long time no see! yes.. rains a bit only a bit  lol  i'm fine thanks  how's you ?|2009|04   |06 |2009-04-06|\n",
      "+-------------+----------+----------------------------+--------+----+------------------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "url_pattern = r'(https?://\\S+|www\\.\\S+)'\n",
    "\n",
    "# Use regexp_replace to remove URLs from the \"Tweet_Text\" column\n",
    "df = df.withColumn(\"Tweet_Text\", regexp_replace(col(\"Tweet_Text\"), url_pattern, ''))\n",
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39e2ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 147:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------------------+--------+----+---------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "|Primary_Index|Tweet_Id  |Date_Text                   |Flag    |User|Tweet_Text                                                                             |Year|Month|Day|Date      |\n",
      "+-------------+----------+----------------------------+--------+----+---------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "|7            |1467811594|Mon Apr 06 22:20:03 PDT 2009|NO_QUERY|coZZ| hey  long time no see! yes.. rains a bit only a bit  lol  i'm fine thanks  how's you ?|2009|04   |06 |2009-04-06|\n",
      "+-------------+----------+----------------------------+--------+----+---------------------------------------------------------------------------------------+----+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "user_mention_pattern = r'@[\\w]+'\n",
    "\n",
    "# Use regexp_replace to remove user mentions from the \"Tweet_Text\" column\n",
    "df = df.withColumn(\"Tweet_Text\", regexp_replace(col(\"Tweet_Text\"), user_mention_pattern, ''))\n",
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b379fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2023-10-30 22:15:26.011232: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-30 22:15:26.490863: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-30 22:15:26.490908: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-30 22:15:26.493338: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-30 22:15:26.603878: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-30 22:15:26.604300: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 22:15:29.309055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "961db2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_processing(text):\n",
    "    stpword = stopwords.words('english')\n",
    "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ba269a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_df = df[['Tweet_Id', 'Date', 'Tweet_Text']]\n",
    "sentiment_df = final_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "236966a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467811594</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>hey  long time no see! yes.. rains a bit only...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet_Id        Date                                         Tweet_Text\n",
       "0  1467811594  2009-04-06   hey  long time no see! yes.. rains a bit only..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bcc98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time: 2023-10-30 22:15:35\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(\"Current date and time:\", formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5052a3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Tweet_Text_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467811594</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>hey  long time no see! yes.. rains a bit only...</td>\n",
       "      <td>hey long time see yes rains bit bit lol im fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet_Id        Date                                         Tweet_Text  \\\n",
       "0  1467811594  2009-04-06   hey  long time no see! yes.. rains a bit only...   \n",
       "\n",
       "                                  Tweet_Text_Cleaned  \n",
       "0  hey long time see yes rains bit bit lol im fin...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df['Tweet_Text_Cleaned'] = sentiment_df['Tweet_Text'].apply(get_text_processing)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac449df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time: 2023-10-30 22:15:35\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(\"Current date and time:\", formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ee44ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Assuming \"df\" is your Pandas DataFrame\n",
    "sentiment_df[\"Textblob_Sentiment\"] = sentiment_df[\"Tweet_Text_Cleaned\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# The \"Sentiment\" column now contains sentiment polarity scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bda95090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return \"Positive\"\n",
    "    elif polarity < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "sentiment_df[\"Textblob_Sentiment_Class\"] = sentiment_df[\"Textblob_Sentiment\"].apply(classify_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac96e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time: 2023-10-30 22:15:35\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(\"Current date and time:\", formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d53f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Assuming \"df\" is your Pandas DataFrame\n",
    "sentiment_df[\"NLTK_Sentiment_Scores\"] = sentiment_df[\"Tweet_Text_Cleaned\"].apply(lambda x: analyzer.polarity_scores(x))\n",
    "\n",
    "# Extract the sentiment scores (positive, negative, neutral, compound) into separate columns\n",
    "sentiment_df[\"NLTK_Positive_Score\"] = sentiment_df[\"NLTK_Sentiment_Scores\"].apply(lambda x: x[\"pos\"])\n",
    "sentiment_df[\"NLTK_Negative_Score\"] = sentiment_df[\"NLTK_Sentiment_Scores\"].apply(lambda x: x[\"neg\"])\n",
    "sentiment_df[\"NLTK_Neutral_Score\"] = sentiment_df[\"NLTK_Sentiment_Scores\"].apply(lambda x: x[\"neu\"])\n",
    "sentiment_df[\"NLTK_Compound_Score\"] = sentiment_df[\"NLTK_Sentiment_Scores\"].apply(lambda x: x[\"compound\"])\n",
    "\n",
    "# Classify sentiment based on compound score\n",
    "sentiment_df[\"NLTK_Sentiment_Class\"] = sentiment_df[\"NLTK_Compound_Score\"].apply(lambda x: \"Positive\" if x > 0 else \"Negative\" if x < 0 else \"Neutral\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6e4aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time: 2023-10-30 22:19:17\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(\"Current date and time:\", formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6063cebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Tweet_Text_Cleaned</th>\n",
       "      <th>Textblob_Sentiment</th>\n",
       "      <th>Textblob_Sentiment_Class</th>\n",
       "      <th>NLTK_Sentiment_Scores</th>\n",
       "      <th>NLTK_Positive_Score</th>\n",
       "      <th>NLTK_Negative_Score</th>\n",
       "      <th>NLTK_Neutral_Score</th>\n",
       "      <th>NLTK_Compound_Score</th>\n",
       "      <th>NLTK_Sentiment_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467811594</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>hey  long time no see! yes.. rains a bit only...</td>\n",
       "      <td>hey long time see yes rains bit bit lol im fin...</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet_Id        Date                                         Tweet_Text  \\\n",
       "0  1467811594  2009-04-06   hey  long time no see! yes.. rains a bit only...   \n",
       "\n",
       "                                  Tweet_Text_Cleaned  Textblob_Sentiment  \\\n",
       "0  hey long time see yes rains bit bit lol im fin...            0.341667   \n",
       "\n",
       "  Textblob_Sentiment_Class                              NLTK_Sentiment_Scores  \\\n",
       "0                 Positive  {'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...   \n",
       "\n",
       "   NLTK_Positive_Score  NLTK_Negative_Score  NLTK_Neutral_Score  \\\n",
       "0                0.531                  0.0               0.469   \n",
       "\n",
       "   NLTK_Compound_Score NLTK_Sentiment_Class  \n",
       "0               0.8481             Positive  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab264a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
